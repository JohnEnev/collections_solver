{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Evaluation\n",
        "\n",
        "This notebook evaluates all models (base and fine-tuned) on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
        "\n",
        "from evaluation import run_evaluation\n",
        "from utils import load_jsonl, save_json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# base_results = run_evaluation(\n",
        "#     puzzles=test_puzzles,\n",
        "#     model_name=\"gpt-4o-mini\",\n",
        "#     num_trials=3\n",
        "# )\n",
        "# save_json(base_results, '../results/base_summary.json')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
