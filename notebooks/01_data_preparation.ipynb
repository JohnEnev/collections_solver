{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Preparation\n",
    "\n",
    "This notebook handles:\n",
    "1. Loading NYT Connections puzzle data\n",
    "2. Cleaning and validating puzzles\n",
    "3. Creating temporal train/test split\n",
    "4. Preparing training datasets (alpha and beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "random.seed(42)\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Puzzle Data\n",
    "\n",
    "Puzzle format:\n",
    "```json\n",
    "{\n",
    "    \"game_id\": 123,\n",
    "    \"date\": \"2024-01-15\",\n",
    "    \"words\": [\"WORD1\", ..., \"WORD16\"],\n",
    "    \"groups\": [\n",
    "        {\"name\": \"GROUP NAME\", \"members\": [\"W1\", \"W2\", \"W3\", \"W4\"]},\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_puzzles(filepath):\n",
    "    \"\"\"Load puzzles from JSONL, converting to standard format.\"\"\"\n",
    "    puzzles = []\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            raw = json.loads(line)\n",
    "            \n",
    "            # Convert groups to solution dict\n",
    "            solution = {g[\"name\"]: g[\"members\"] for g in raw[\"groups\"]}\n",
    "            \n",
    "            puzzles.append({\n",
    "                \"game_id\": raw[\"game_id\"],\n",
    "                \"date\": raw.get(\"date\"),\n",
    "                \"words\": raw[\"words\"],\n",
    "                \"solution\": solution\n",
    "            })\n",
    "    return puzzles\n",
    "\n",
    "# Load all puzzles\n",
    "puzzles = load_raw_puzzles(DATA_DIR / \"puzzles_raw.jsonl\")\n",
    "print(f\"Loaded {len(puzzles)} puzzles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_puzzle(puzzle):\n",
    "    \"\"\"Check puzzle has valid structure.\"\"\"\n",
    "    # Must have exactly 16 words\n",
    "    if len(puzzle[\"words\"]) != 16:\n",
    "        return False, f\"Wrong word count: {len(puzzle['words'])}\"\n",
    "    \n",
    "    # Must have exactly 4 groups\n",
    "    if len(puzzle[\"solution\"]) != 4:\n",
    "        return False, f\"Wrong group count: {len(puzzle['solution'])}\"\n",
    "    \n",
    "    # Each group must have 4 words\n",
    "    for name, members in puzzle[\"solution\"].items():\n",
    "        if len(members) != 4:\n",
    "            return False, f\"Group '{name}' has {len(members)} words\"\n",
    "    \n",
    "    # All solution words must be in word list\n",
    "    word_set = set(w.upper() for w in puzzle[\"words\"])\n",
    "    for name, members in puzzle[\"solution\"].items():\n",
    "        for m in members:\n",
    "            if m.upper() not in word_set:\n",
    "                return False, f\"Solution word '{m}' not in word list\"\n",
    "    \n",
    "    # No NaN values\n",
    "    for w in puzzle[\"words\"]:\n",
    "        if w is None or (isinstance(w, float) and str(w) == 'nan'):\n",
    "            return False, \"Contains NaN values\"\n",
    "    \n",
    "    return True, None\n",
    "\n",
    "# Validate all puzzles\n",
    "valid_puzzles = []\n",
    "invalid_count = 0\n",
    "\n",
    "for p in puzzles:\n",
    "    is_valid, error = validate_puzzle(p)\n",
    "    if is_valid:\n",
    "        valid_puzzles.append(p)\n",
    "    else:\n",
    "        invalid_count += 1\n",
    "        print(f\"Invalid puzzle {p['game_id']}: {error}\")\n",
    "\n",
    "print(f\"\\nValid: {len(valid_puzzles)}, Invalid: {invalid_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Temporal Train/Test Split\n",
    "\n",
    "We use a **temporal split**: train on older puzzles, test on newer ones.\n",
    "This simulates real deployment (model trained on past, predicting future)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by game_id (chronological)\n",
    "valid_puzzles.sort(key=lambda x: x[\"game_id\"])\n",
    "\n",
    "# Last 150 puzzles for test\n",
    "TEST_SIZE = 150\n",
    "train_puzzles = valid_puzzles[:-TEST_SIZE]\n",
    "test_puzzles = valid_puzzles[-TEST_SIZE:]\n",
    "\n",
    "test_ids = set(p[\"game_id\"] for p in test_puzzles)\n",
    "\n",
    "print(f\"Train: {len(train_puzzles)} puzzles (IDs {train_puzzles[0]['game_id']}-{train_puzzles[-1]['game_id']})\")\n",
    "print(f\"Test:  {len(test_puzzles)} puzzles (IDs {test_puzzles[0]['game_id']}-{test_puzzles[-1]['game_id']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train/test splits\n",
    "def save_jsonl(data, filepath):\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "save_jsonl(train_puzzles, DATA_DIR / \"train.jsonl\")\n",
    "save_jsonl(test_puzzles, DATA_DIR / \"test.jsonl\")\n",
    "\n",
    "print(f\"Saved {DATA_DIR / 'train.jsonl'} ({len(train_puzzles)} puzzles)\")\n",
    "print(f\"Saved {DATA_DIR / 'test.jsonl'} ({len(test_puzzles)} puzzles)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data\n",
    "\n",
    "We have two types of training data:\n",
    "1. **Golden traces**: One-shot reasoning from Claude Sonnet\n",
    "2. **Game traces**: Multi-turn game transcripts with feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load golden traces (generated separately)\n",
    "golden_traces = []\n",
    "with open(DATA_DIR / \"golden_traces.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            golden_traces.append(json.loads(line))\n",
    "\n",
    "# Check for leakage into test set\n",
    "golden_ids = set(int(t[\"game_id\"]) for t in golden_traces)\n",
    "golden_leakage = golden_ids & test_ids\n",
    "\n",
    "print(f\"Golden traces: {len(golden_traces)} total, {len(golden_leakage)} in test set\")\n",
    "if golden_leakage:\n",
    "    print(f\"⚠️  WARNING: {len(golden_leakage)} golden traces leak into test!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load game traces\n",
    "game_traces = []\n",
    "with open(DATA_DIR / \"game_traces.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            game_traces.append(json.loads(line))\n",
    "\n",
    "# Filter to only clean traces (not in test set)\n",
    "game_ids = [int(t[\"metadata\"][\"puzzle_id\"]) for t in game_traces]\n",
    "clean_game_traces = [t for t in game_traces if int(t[\"metadata\"][\"puzzle_id\"]) not in test_ids]\n",
    "\n",
    "print(f\"Game traces: {len(game_traces)} total, {len(clean_game_traces)} clean (not in test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format golden traces for SFT\n",
    "SYSTEM_PROMPT = \"You are an expert puzzle solver specializing in word associations and pattern recognition.\"\n",
    "\n",
    "def format_golden_trace(trace):\n",
    "    \"\"\"Convert golden trace to chat format.\"\"\"\n",
    "    words_str = \", \".join(trace[\"words\"])\n",
    "    prompt = f\"\"\"Solve this NYT Connections puzzle. Group the 16 words into 4 groups of 4 words each.\n",
    "\n",
    "Words: {words_str}\n",
    "\n",
    "Think through this step-by-step, then output your answer as JSON.\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": trace[\"reasoning_trace\"]}\n",
    "        ],\n",
    "        \"metadata\": {\n",
    "            \"puzzle_id\": trace.get(\"game_id\", 0),\n",
    "            \"source\": \"golden_trace\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "golden_formatted = [format_golden_trace(t) for t in golden_traces]\n",
    "print(f\"Formatted {len(golden_formatted)} golden traces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Alpha dataset (golden only)\n",
    "alpha_data = golden_formatted.copy()\n",
    "random.shuffle(alpha_data)\n",
    "\n",
    "save_jsonl(alpha_data, DATA_DIR / \"sft_alpha.jsonl\")\n",
    "print(f\"Alpha training data: {len(alpha_data)} examples (golden only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Beta dataset (golden + game traces)\n",
    "# Take first 150 clean game traces\n",
    "game_traces_to_use = clean_game_traces[:150]\n",
    "\n",
    "beta_data = golden_formatted + game_traces_to_use\n",
    "random.shuffle(beta_data)\n",
    "\n",
    "save_jsonl(beta_data, DATA_DIR / \"sft_beta.jsonl\")\n",
    "print(f\"Beta training data: {len(beta_data)} examples ({len(golden_formatted)} golden + {len(game_traces_to_use)} game)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Created files:\n",
    "- `data/train.jsonl` - Training puzzles (for reference)\n",
    "- `data/test.jsonl` - Test puzzles (150, temporal split)\n",
    "- `data/sft_alpha.jsonl` - Alpha training data (golden traces only)\n",
    "- `data/sft_beta.jsonl` - Beta training data (golden + game traces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
